{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/Documentos/image-labeling-author-profiling/venv/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from wordcloud import WordCloud\n",
    "from train_models import create_avg_dataset\n",
    "from collections import OrderedDict\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.17650938034058 seconds to read csv's and create all dataframes\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH_DATA = '/media/ivan/DDE/datasets_proyecto_mt'\n",
    "train_data_csv_paths = ['/datasets/en_train.csv', './datasets/es_train.csv', './datasets/ar_train.csv']\n",
    "train_labels_json_paths = ['./authors_labels/en_train_labels.json', './authors_labels/es_train_labels.json','./authors_labels/ar_train_labels.json']\n",
    "X_dataframes = [None for i in range(len(train_data_csv_paths))]\n",
    "y_dataframes = [None for i in range(len(train_labels_json_paths))]\n",
    "list_of_ids = [None for i in range(len(X_dataframes))]\n",
    "authors_ids = []\n",
    "i = 0\n",
    "t_start = time()\n",
    "for path_x, path_y in zip(train_data_csv_paths, train_labels_json_paths):\n",
    "    list_of_ids[i] = path_x.strip().split('/')[2][:2]\n",
    "    X_dataframes[i] = pd.read_csv(BASE_PATH_DATA + path_x, sep='\\s*,\\s*', header=0, encoding='ascii', engine='python')\n",
    "#     X, y_dataframes[i] = create_avg_dataset(X, path_y)\n",
    "#     y_pred_dict = OrderedDict([(\"class\", y_dataframes[i])])\n",
    "#     X_dataframes[i] = pd.concat([X.reset_index(drop=True), pd.DataFrame.from_dict(y_pred_dict)], axis=1)\n",
    "    i += 1\n",
    "print(\"{} seconds to read csv's and create all dataframes\".format(time() - t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = [\"en\", \"es\", \"ar\"]\n",
    "# interesting_labels = set([\"miniskirt\", \"velvet\", \"hair_spray\", \"maillot.1\", \"wig\", \"bikini\", \"stole\", \"brassiere\", \"scoreboard\", \"feather_boa\", \"bath_towel\", \"airliner\", \"silky_terrier\", \"bonnet\", \"bulletproof_vest\", \"maillot\", \"Model_T\", \"sarong\", \"overskirt\", \"shower_curtain\", \"hoopskirt\", \"lipstick\", \"plate_rack\", \"hand_blower\", \"Lhasa\", \"wig\", \"velvet\", \"bath_towel\", \"lipstick\", \"feather_boa\", \"bonnet\", \"face_powder\", \"stole\", \"tub\", \"milk_can\", \"bathtub\", \"overskirt\", \"golden_retriever\", \"Angora\", \"birdhouse\", \"fur_coat\", \"bikini\", \"Maltese_dog\", \"brassiere\", \"hair_spray\", \"lawn_mower\", \"ice_lolly\", \"maillot.1\", \"hair_slide\", \"chain_saw\", \"ballplayer\", \"velvet\", \"cradle\", \"brassiere\", \"broccoli\", \"lynx\", \"red-backed_sandpiper\", \"chiffonier\", \"Border_terrier\", \"lipstick\", \"miniskirt\", \"African_chameleon\", \"bath_towel\", \"safety_pin\", \"sea_urchin\", \"vase\", \"lighter\", \"football_helmet\", \"snorkel\", \"coyote\", \"ant\", \"pot\", \"shield\", \"military_uniform\", \"paddle\"])\n",
    "# interesting_labels = set([\"brassiere\", \"velvet\", \"bath_towel\", \"lipstick\"])\n",
    "interesting_labels = set([\"Windsor_tie\"])\n",
    "images_paths = []\n",
    "# with open(\"authors_candidates_for_classification_brassiere.txt\", \"w\") as file:\n",
    "threshold = 0.7\n",
    "for i in range(len(X_dataframes)):\n",
    "#         file.write(labels[i] + \"\\n\\n\")\n",
    "    for index, row in X_dataframes[i].iterrows():\n",
    "        for label in interesting_labels:\n",
    "            if row[label] > threshold and row['class'] == 'male':\n",
    "#                     file.write(\"author_id = {} image_idx = {} class = {}\\n\".format(row['author_id'], index, row['class']))\n",
    "#                     file.write(\"{} = {} \\n\".format(label, row[label]))\n",
    "#                     file.write(\"{}\\n\\n\".format(decode_predictions(np.array([row.drop([\"author_id\", \"class\"])]), top=3)[0]))\n",
    "                images_paths.append(labels[i] + '/photo/' + row['author_id'])\n",
    "# print(images_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ivan/Documentos/image-labeling-author-profiling/venv/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "MODEL = VGG16(weights='imagenet', include_top=True)\n",
    "# image = load_img('1cccf94761df573219c3ca96e8abbec1.8.jpeg', target_size=(224, 224))\n",
    "# image = img_to_array(image)\n",
    "# image = np.expand_dims(image, axis=0)\n",
    "# image = preprocess_input(image)\n",
    "# features = MODEL.predict(image)\n",
    "# x = np.reshape(features, 7*7*512)\n",
    "# print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "from os.path import isfile, join\n",
    "BASE_DIR_IMAGES = '/media/ivan/5a98638f-057c-4499-87fa-d0d7b41f24b4/home/ivan/pan18-author-profiling-training-2018-02-27/'\n",
    "# os.mkdir(BASE_PATH_DATA + '/images_bra')\n",
    "for author_dir in set(images_paths):\n",
    "    language = author_dir[:2]\n",
    "    images = [f for f in os.listdir(BASE_DIR_IMAGES + author_dir)]\n",
    "    for img in images:\n",
    "        try:\n",
    "            file = join(BASE_DIR_IMAGES, join(author_dir, img))\n",
    "            image = load_img(file, target_size=(224, 224))\n",
    "            image = img_to_array(image)\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "            image = preprocess_input(image)\n",
    "            features = MODEL.predict(image)\n",
    "            decoded = [t[1] for t in decode_predictions(features, top=3)[0]]\n",
    "            if 'windsor_tie' in decoded:\n",
    "                shutil.copy(file, BASE_PATH_DATA + '/Windsor_tie/' + language)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_image_representation(image_representation):\n",
    "    models_dir = './models/'\n",
    "    models_files_paths = [join(models_dir, f) for f in listdir(models_dir) if isfile(join(models_dir, f))]\n",
    "    loaded_models = [joblib.load(model_path) for model_path in models_files_paths]\n",
    "    predicted_gender = []\n",
    "    genders = {\"female\" : 0, \"male\" : 0}\n",
    "    model_male_predictor = []\n",
    "    model_female_predictor = []\n",
    "    for model_idx in range(len(loaded_models)):\n",
    "        models_split = models_files_paths[model_idx].replace(models_dir, \"\") \n",
    "        models_split = models_files_paths[model_idx].strip().split('_')\n",
    "        ids_models = []\n",
    "        for s in models_split:\n",
    "            if s == \"svm\":\n",
    "                break\n",
    "            ids_models.append(s)\n",
    "        ids_models[0] = ids_models[0][-2:]\n",
    "#         print(\"Using trained model {}\".format(ids_models))\n",
    "        y = loaded_models[model_idx].predict(image_representation)[0]\n",
    "        genders[y] += 1\n",
    "        if y == \"male\":\n",
    "            model_female_predictor.append(\"-\".join(ids_models))\n",
    "    if genders[\"female\"] == 7:\n",
    "        print(\"All models predicted: female\")\n",
    "    else:\n",
    "        print(\"Excepto: {}\".format(\", \".join(model_female_predictor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ivan/Escritorio/test_images/36f46347bd3cbd53d4535574a316c9b8.2.jpeg\n",
      "Attributes (top 3): \n",
      "* lipstick\n",
      "* bikini\n",
      "* brassiere\n",
      "Gender: female\n",
      "All models predicted: female\n",
      "/home/ivan/Escritorio/test_images/4d04cd62a711c5a8229659b5b505e634.0.jpeg\n",
      "Attributes (top 3): \n",
      "* cloak\n",
      "* overskirt\n",
      "* velvet\n",
      "Gender: female\n",
      "All models predicted: female\n",
      "/home/ivan/Escritorio/test_images/4d2276bf535fd6ea6da0ae85c97b9ff7.8.jpeg\n",
      "Attributes (top 3): \n",
      "* velvet\n",
      "* doormat\n",
      "* birdhouse\n",
      "Gender: female\n",
      "All models predicted: female\n",
      "/home/ivan/Escritorio/test_images/106086df9c362aa4dcf4c824ada0dc05.1.jpeg\n",
      "Attributes (top 3): \n",
      "* pillow\n",
      "* coral_reef\n",
      "* velvet\n",
      "Gender: female\n",
      "All models predicted: female\n",
      "/home/ivan/Escritorio/test_images/3ed1ce5866f31b50a902121cd2e27e0d.0.jpeg\n",
      "Attributes (top 3): \n",
      "* lipstick\n",
      "* brassiere\n",
      "* wig\n",
      "Gender: female\n",
      "All models predicted: female\n",
      "/home/ivan/Escritorio/test_images/e62e683a17bc461c68b9bac8d7771820.0.jpeg\n",
      "Attributes (top 3): \n",
      "* velvet\n",
      "* vestment\n",
      "* quilt\n",
      "Gender: female\n",
      "All models predicted: female\n",
      "/home/ivan/Escritorio/test_images/a5c6506fc31fdcbb839226a740367332.3.jpeg\n",
      "Attributes (top 3): \n",
      "* lipstick\n",
      "* rubber_eraser\n",
      "* face_powder\n",
      "Gender: female\n",
      "All models predicted: female\n"
     ]
    }
   ],
   "source": [
    "img_dir = '/home/ivan/Escritorio/test_images/'\n",
    "img_files = [join(img_dir, f) for f in listdir(img_dir) if isfile(join(img_dir, f))]\n",
    "for image_path in img_files:\n",
    "    print(image_path)\n",
    "    image = load_img(image_path, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = preprocess_input(image)\n",
    "    features = MODEL.predict(image)\n",
    "    decoded = [t[1] for t in decode_predictions(features, top=3)[0]]\n",
    "    print('Attributes (top 3): \\n* {}'.format(\"\\n* \".join(decoded)))\n",
    "    print(\"Gender: female\")\n",
    "    evaluate_image_representation(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
